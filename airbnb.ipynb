import requests
from bs4 import BeautifulSoup
href_list = []
response = requests.get("http://insideairbnb.com/get-the-data.html")
html = BeautifulSoup(response.text)
regions = html.find_all("table")
for r in regions:
    cell = r.find("tbody").find_all("tr")[3].find_all("td")[2].find("a")
    href_list.append(cell["href"])

from urllib.request import urlretrieve
for h in href_list[:10]:
    print(h.split("/")[-4], h)
    fname = "airbnb/" + h.split("/")[-4] + ".csv"
    urlretrieve(h, fname)
    
import glob
import pandas as pd
df = pd.DataFrame()
for fn in glob.glob("airbnb/*.csv"):
    c = pd.read_csv(fn, encoding="utf-8")
    df = pd.concat([df, c])
df.reset_index()

result = pd.DataFrame()
temp = df.groupby("host_id").count().reset_index()
result["host_id"] = temp["host_id"]
result["count"] = temp["id"]
result

final = result[result["count"] >= 2].reset_index()
final.to_csv("final.csv", encoding="utf-8", index=False)
final

