import requests
from bs4 import BeautifulSoup
href_list = []
response = requests.get("http://insideairbnb.com/get-the-data.html")
html = BeautifulSoup(response.text)
regions = html.find_all("table")
for r in regions:
    cell = r.find("tbody").find_all("tr")[3].find_all("td")[2].find("a")
    href_list.append(cell["href"])
    
from urllib.request import urlretrieve
for h in href_list[:10]:
    print(h.split("/")[-4], h)
    fname = "airbnb/" + h.split("/")[-4] + ".csv"
    urlretrieve(h, fname)
    
import glob
import pandas as pd
df = pd.DataFrame()
for fn in glob.glob("airbnb/*.csv"):
    c = pd.read_csv(fn, encoding="utf-8")
    df = pd.concat([df, c])
df.reset_index()
